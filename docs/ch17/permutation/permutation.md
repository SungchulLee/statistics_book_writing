# Permutation Tests

## Introduction

The **Permutation Test** (or Randomization Test) is a versatile non-parametric method for hypothesis testing. It evaluates whether an observed test statistic is consistent with the null hypothesis by comparing it to a distribution generated by rearrangements (permutations) of the data. This method does not rely on assumptions about the data's underlying distribution.

### Key Features

1. **Assumption-Free**: Does not assume normality or homogeneity of variances. The distribution of the test statistic is determined entirely from the data.
2. **Flexible**: Can be used for comparing means, medians, variances, correlations, or other statistics.
3. **Exact Test**: For small sample sizes, the test is exact because it considers all possible permutations.
4. **Approximate Test**: For larger datasets, an approximation can be made by sampling a subset of permutations.

---

## Hypotheses

- **Null Hypothesis ($H_0$)**: The observed data come from the same distribution, or the test statistic is not associated with the grouping variable.
- **Alternative Hypothesis ($H_1$)**: The observed data come from different distributions, or the test statistic is associated with the grouping variable.

---

## General Steps

### Step 1: Choose a Test Statistic

Select a statistic that reflects the effect or difference you are testing, such as the mean difference, median difference, or correlation.

### Step 2: Calculate the Observed Test Statistic

Compute the test statistic for the original dataset.

### Step 3: Generate Permutations

Shuffle (permute) the data labels or group assignments randomly to break any existing association between groups.

### Step 4: Compute Test Statistics for Permutations

For each permutation, compute the test statistic.

### Step 5: Compare the Observed Statistic

Compare the observed statistic to the distribution of test statistics from the permutations. Compute a p-value as the proportion of permutations where the test statistic is at least as extreme as the observed statistic.

---

## Permutation Test for Mean Difference

### Example

**Data:**

- Group A: $[8, 7, 9, 10, 6]$
- Group B: $[5, 6, 4, 3, 7]$

**Hypotheses:**

- $H_0$: The means of the two groups are equal.
- $H_1$: The means of the two groups are not equal.

```python
import numpy as np
import matplotlib.pyplot as plt

def permutation_test(group_a, group_b, n_permutations=10000):
    """
    Perform a permutation test for the difference in means.

    Parameters:
    - group_a, group_b: Data for each group.
    - n_permutations: Number of permutations.

    Returns:
    - p_value: The p-value for the test.
    - observed_diff: The observed difference in means.
    - perm_differences: Distribution of permuted differences.
    """
    combined = np.concatenate([group_a, group_b])
    observed_diff = np.mean(group_a) - np.mean(group_b)

    perm_differences = []
    for _ in range(n_permutations):
        np.random.shuffle(combined)
        perm_group_a = combined[:len(group_a)]
        perm_group_b = combined[len(group_a):]
        perm_diff = np.mean(perm_group_a) - np.mean(perm_group_b)
        perm_differences.append(perm_diff)

    perm_differences = np.array(perm_differences)
    p_value = np.mean(np.abs(perm_differences) >= np.abs(observed_diff))

    return p_value, observed_diff, perm_differences

# Run the test
group_a = np.array([8, 7, 9, 10, 6])
group_b = np.array([5, 6, 4, 3, 7])

p_value, observed_diff, perm_dist = permutation_test(group_a, group_b)

print(f"Observed Difference in Means: {observed_diff:.2f}")
print(f"P-value: {p_value:.4f}")

# Visualize
fig, ax = plt.subplots(figsize=(10, 4))
ax.hist(perm_dist, bins=50, edgecolor='black', alpha=0.7, label='Permutation Distribution')
ax.axvline(observed_diff, color='red', linestyle='--', linewidth=2,
           label=f'Observed = {observed_diff:.2f}')
ax.axvline(-observed_diff, color='red', linestyle='--', linewidth=2)
ax.legend()
ax.set_xlabel('Difference in Means')
ax.set_ylabel('Frequency')
ax.set_title('Permutation Test Distribution')
plt.show()
```

**Example Output:**

```
Observed Difference in Means: 3.00
P-value: 0.0182
```

The p-value suggests a statistically significant difference at the 5% level.

---

## Permutation Test for Correlation

Test whether the observed correlation between two variables is significant:

```python
import numpy as np

def permutation_correlation_test(x, y, n_permutations=10000):
    """
    Permutation test for correlation significance.

    Parameters:
    - x, y: Paired data arrays.
    - n_permutations: Number of permutations.

    Returns:
    - p_value, observed_corr, perm_corrs
    """
    observed_corr = np.corrcoef(x, y)[0, 1]

    perm_corrs = []
    for _ in range(n_permutations):
        y_perm = np.random.permutation(y)
        perm_corrs.append(np.corrcoef(x, y_perm)[0, 1])

    perm_corrs = np.array(perm_corrs)
    p_value = np.mean(np.abs(perm_corrs) >= np.abs(observed_corr))

    return p_value, observed_corr, perm_corrs

x = np.array([1, 2, 3, 4, 5, 6, 7, 8])
y = np.array([2, 3, 5, 4, 6, 8, 7, 9])

p_value, observed_corr, _ = permutation_correlation_test(x, y)
print(f"Observed Correlation: {observed_corr:.4f}")
print(f"Permutation P-value: {p_value:.4f}")
```

---

## Permutation Test for Paired Data

For paired data, permute the **signs** of the differences rather than shuffling group labels:

```python
import numpy as np

def paired_permutation_test(before, after, n_permutations=10000):
    """
    Permutation test for paired data.

    Parameters:
    - before, after: Paired measurements.
    - n_permutations: Number of permutations.

    Returns:
    - p_value, observed_mean_diff
    """
    differences = np.array(after) - np.array(before)
    observed_mean_diff = np.mean(differences)

    perm_means = []
    for _ in range(n_permutations):
        signs = np.random.choice([-1, 1], size=len(differences))
        perm_means.append(np.mean(differences * signs))

    perm_means = np.array(perm_means)
    p_value = np.mean(np.abs(perm_means) >= np.abs(observed_mean_diff))

    return p_value, observed_mean_diff

before = [70, 68, 75, 80, 72, 74, 69, 77, 73, 76]
after = [72, 69, 78, 85, 75, 76, 70, 79, 74, 80]

p_value, obs_diff = paired_permutation_test(before, after)
print(f"Observed Mean Difference: {obs_diff:.2f}")
print(f"P-value: {p_value:.4f}")
```

---

## Exact vs Approximate Permutation Tests

| Aspect | Exact | Approximate |
|---|---|---|
| **Method** | Enumerate all possible permutations | Random subset of permutations |
| **Feasibility** | Small samples only ($n \leq 20$) | Any sample size |
| **Number of permutations** | $\binom{n_1 + n_2}{n_1}$ for two-sample | User-specified (e.g., 10,000) |
| **P-value** | Exact | Approximate (improves with more permutations) |

For two groups of size 5, there are $\binom{10}{5} = 252$ possible permutations â€” feasible to enumerate exactly. For larger samples, 10,000+ random permutations typically suffice.

---

## Pros and Cons

| Pros | Cons |
|---|---|
| No distributional assumptions | Computationally intensive for large data |
| Exact for small datasets | Accuracy depends on number of permutations |
| Flexible for any test statistic | Paired data requires modification |
| Robust with unequal variances/sample sizes | Less intuitive for complex statistics than bootstrap |

---

## Applications

1. **Testing Mean or Median Differences**: Compare groups without assuming normality.
2. **Correlation Testing**: Test significance of correlation coefficients.
3. **Feature Selection**: Identify important variables in machine learning or predictive models.
4. **Genomics and Biology**: Widely used in high-dimensional data analysis, such as gene expression studies.
5. **Time Series**: Block permutation tests for dependent data.
